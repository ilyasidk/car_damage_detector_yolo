import torch
import cv2
import numpy as np
from ultralytics import YOLO
import onnxruntime as ort
from PIL import Image
import matplotlib.pyplot as plt
import os

class TwoStageDamageDetection:
    def __init__(self, yolo_model_path, classifier_onnx_path):
        """
        Two-stage damage detection system:
        1. YOLO - damage detection (3 classes: dirt, scratch, dent)
        2. Classifier - severity classification (6 classes)
        """
        print("Initializing two-stage system...")
        
        # Load YOLO model
        print("Loading YOLO model...")
        self.yolo_model = YOLO(yolo_model_path)
        
        # Load ONNX classifier
        print("Loading ONNX classifier...")
        self.classifier_session = ort.InferenceSession(classifier_onnx_path)
        
        # YOLO classes (3 classes)
        self.yolo_classes = ['dirt', 'scratch', 'dent']
        
        # Classifier classes (6 classes)
        self.classifier_classes = [
            'dirt', 'scratch_low', 'scratch_med', 'scratch_high', 
            'dent_low', 'dent_med', 'dent_high'
        ]
        
        # Transformations for classifier
        self.transform = self._get_transform()
        
        print("System initialized!")
    
    def _get_transform(self):
        """Returns transformations for classifier"""
        from torchvision import transforms
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def detect_damages(self, image_path, confidence_threshold=0.3):
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é YOLO
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            confidence_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏ –∫–ª–∞—Å—Å–∞–º–∏
        """
        print(f"üîç –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –≤ {image_path}...")
        
        # YOLO –¥–µ—Ç–µ–∫—Ü–∏—è
        results = self.yolo_model(image_path, conf=confidence_threshold)
        
        detections = []
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = box.conf[0].cpu().numpy()
                    class_id = int(box.cls[0].cpu().numpy())
                    
                    detection = {
                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(confidence),
                        'yolo_class': self.yolo_classes[class_id],
                        'class_id': class_id
                    }
                    detections.append(detection)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(detections)} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
        return detections
    
    def classify_severity(self, image_path, detections):
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è scratch –∏ dent
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            detections: —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π –æ—Ç YOLO
            
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏
        """
        if not detections:
            return detections
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ scratch –∏ dent –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        scratch_dent_detections = [d for d in detections if d['yolo_class'] in ['scratch', 'dent']]
        dirt_detections = [d for d in detections if d['yolo_class'] == 'dirt']
        
        print(f"üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏ –¥–ª—è {len(scratch_dent_detections)} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π (scratch/dent)...")
        print(f"üìù –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {len(dirt_detections)} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π —Ç–∏–ø–∞ dirt")
        
        enhanced_detections = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º dirt - –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        for detection in dirt_detections:
            enhanced_detection = detection.copy()
            enhanced_detection['severity_class'] = 'dirt'  # –î–ª—è dirt –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            enhanced_detection['severity_confidence'] = detection['confidence']  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å YOLO
            enhanced_detections.append(enhanced_detection)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º scratch –∏ dent - —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
        if scratch_dent_detections:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = cv2.imread(image_path)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            for detection in scratch_dent_detections:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º ROI
                x1, y1, x2, y2 = detection['bbox']
                roi = image_rgb[y1:y2, x1:x2]
                
                if roi.size == 0:
                    continue
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ROI –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                roi_pil = Image.fromarray(roi)
                roi_tensor = self.transform(roi_pil).unsqueeze(0)
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                severity_class, severity_confidence = self._classify_roi(roi_tensor)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏
                enhanced_detection = detection.copy()
                enhanced_detection['severity_class'] = severity_class
                enhanced_detection['severity_confidence'] = severity_confidence
                
                enhanced_detections.append(enhanced_detection)
        
        print(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {len(enhanced_detections)} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
        return enhanced_detections
    
    def _classify_roi(self, roi_tensor):
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ROI —Å –ø–æ–º–æ—â—å—é ONNX –º–æ–¥–µ–ª–∏
        
        Args:
            roi_tensor: —Ç–µ–Ω–∑–æ—Ä ROI (1, 3, 224, 224)
            
        Returns:
            tuple: (–∫–ª–∞—Å—Å, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
        input_data = roi_tensor.numpy()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º ONNX –º–æ–¥–µ–ª—å
        input_name = self.classifier_session.get_inputs()[0].name
        output_name = self.classifier_session.get_outputs()[0].name
        
        outputs = self.classifier_session.run([output_name], {input_name: input_data})
        predictions = outputs[0][0]
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        class_id = np.argmax(predictions)
        confidence = float(predictions[class_id])
        
        return self.classifier_classes[class_id], confidence
    
    def process_image(self, image_path, confidence_threshold=0.3, save_result=True):
        """
        –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –¥–µ—Ç–µ–∫—Ü–∏—è + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            confidence_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è YOLO
            save_result: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            
        Returns:
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        print(f"\nüñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {os.path.basename(image_path)}")
        
        # –≠—Ç–∞–ø 1: –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        detections = self.detect_damages(image_path, confidence_threshold)
        
        if not detections:
            print("‚ùå –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return {
                'image_path': image_path,
                'detections': [],
                'summary': '–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'
            }
        
        # –≠—Ç–∞–ø 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏
        enhanced_detections = self.classify_severity(image_path, detections)
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
        summary = self._create_summary(enhanced_detections)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if save_result:
            self._save_result(image_path, enhanced_detections, summary)
        
        return {
            'image_path': image_path,
            'detections': enhanced_detections,
            'summary': summary
        }
    
    def _create_summary(self, detections):
        """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –¥–µ—Ç–µ–∫—Ü–∏—è–º"""
        if not detections:
            return "–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        type_counts = {}
        severity_counts = {}
        
        for det in detections:
            yolo_class = det['yolo_class']
            severity = det['severity_class']
            
            type_counts[yolo_class] = type_counts.get(yolo_class, 0) + 1
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç —Å–≤–æ–¥–∫–∏
        summary = f"–ù–∞–π–¥–µ–Ω–æ {len(detections)} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π:\n"
        
        summary += "\n–ü–æ —Ç–∏–ø–∞–º:\n"
        for type_name, count in type_counts.items():
            summary += f"  - {type_name}: {count}\n"
        
        summary += "\n–ü–æ —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏:\n"
        for severity, count in severity_counts.items():
            summary += f"  - {severity}: {count}\n"
        
        return summary
    
    def _save_result(self, image_path, detections, summary):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # –†–∏—Å—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
        for i, det in enumerate(detections):
            x1, y1, x2, y2 = det['bbox']
            yolo_class = det['yolo_class']
            severity = det['severity_class']
            confidence = det['confidence']
            severity_conf = det['severity_confidence']
            
            # –¶–≤–µ—Ç –¥–ª—è —Ç–∏–ø–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è
            colors = {'dirt': (255, 0, 0), 'scratch': (0, 255, 0), 'dent': (0, 0, 255)}
            color = colors.get(yolo_class, (128, 128, 128))
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(image_rgb, (x1, y1), (x2, y2), color, 2)
            
            # –¢–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            label = f"{yolo_class} ({severity})"
            conf_text = f"YOLO: {confidence:.2f}, Severity: {severity_conf:.2f}"
            
            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(image_rgb, (x1, y1-40), (x1+len(label)*10, y1), color, -1)
            cv2.rectangle(image_rgb, (x1, y1-20), (x1+len(conf_text)*8, y1-20), color, -1)
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(image_rgb, label, (x1, y1-25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            cv2.putText(image_rgb, conf_text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_path = f"two_stage_result_{os.path.basename(image_path)}"
        plt.figure(figsize=(12, 8))
        plt.imshow(image_rgb)
        plt.axis('off')
        plt.title(f"–î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è: {os.path.basename(image_path)}")
        plt.tight_layout()
        plt.savefig(result_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å–≤–æ–¥–∫—É
        summary_path = f"two_stage_summary_{os.path.basename(image_path)}.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {result_path}")
        print(f"üìù –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π")
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    yolo_model_path = "yolo_training_3class_optimized/3class_detection_optimized/weights/best.pt"
    classifier_onnx_path = "onnx_models/severity_classifier.onnx"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(yolo_model_path):
        print(f"‚ùå YOLO –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {yolo_model_path}")
        return
    
    if not os.path.exists(classifier_onnx_path):
        print(f"‚ùå ONNX –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {classifier_onnx_path}")
        return
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    system = TwoStageDamageDetection(yolo_model_path, classifier_onnx_path)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
    test_images = [
        "cars/00010.jpg",
        "cars/00020.jpg", 
        "cars/00030.jpg"
    ]
    
    for image_path in test_images:
        if os.path.exists(image_path):
            print(f"\n{'='*60}")
            result = system.process_image(image_path, confidence_threshold=0.3)
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
            print(result['summary'])
        else:
            print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")

if __name__ == "__main__":
    main()
