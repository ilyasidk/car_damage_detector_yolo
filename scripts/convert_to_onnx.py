#!/usr/bin/env python3
"""
–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –≤ ONNX —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –≤–µ–±-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
"""

import os
import torch
from ultralytics import YOLO
import onnx
import onnxruntime as ort

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
YOLO_MODEL_PATH = "yolo_training_3class_optimized/3class_detection_optimized/weights/best.pt"
SEVERITY_MODEL_PATH = "severity_classifier_best.pth"
OUTPUT_DIR = "onnx_models"

def convert_yolo_to_onnx():
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç YOLO –º–æ–¥–µ–ª—å –≤ ONNX"""
    print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º YOLO –º–æ–¥–µ–ª—å –≤ ONNX...")
    
    if not os.path.exists(YOLO_MODEL_PATH):
        print(f"‚ùå YOLO –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {YOLO_MODEL_PATH}")
        return None
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º YOLO –º–æ–¥–µ–ª—å
    model = YOLO(YOLO_MODEL_PATH)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ONNX
    onnx_path = os.path.join(OUTPUT_DIR, "yolo_3class.onnx")
    try:
        model.export(format="onnx", imgsz=640, dynamic=True, simplify=True)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ñ–∞–π–ª
        if os.path.exists("best.onnx"):
            os.rename("best.onnx", onnx_path)
            print(f"‚úÖ YOLO –º–æ–¥–µ–ª—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞: {onnx_path}")
            return onnx_path
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ YOLO –º–æ–¥–µ–ª–∏")
            return None
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ YOLO: {e}")
        return None

def convert_classifier_to_onnx():
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤ ONNX"""
    print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤ ONNX...")
    
    if not os.path.exists(SEVERITY_MODEL_PATH):
        print(f"‚ùå –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {SEVERITY_MODEL_PATH}")
        return None
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        checkpoint = torch.load(SEVERITY_MODEL_PATH, map_location='cpu')
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º ResNet –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É)
        import torchvision.models as models
        model = models.resnet50(pretrained=False)
        model.fc = torch.nn.Linear(model.fc.in_features, 7)  # 7 –∫–ª–∞—Å—Å–æ–≤
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                model.load_state_dict(checkpoint)
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–∞
        dummy_input = torch.randn(1, 3, 224, 224)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ONNX
        onnx_path = os.path.join(OUTPUT_DIR, "severity_classifier.onnx")
        torch.onnx.export(
            model,
            dummy_input,
            onnx_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        print(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {onnx_path}")
        return onnx_path
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {e}")
        return None

def test_onnx_models(yolo_onnx_path, classifier_onnx_path):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç ONNX –º–æ–¥–µ–ª–∏"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º ONNX –º–æ–¥–µ–ª–∏...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º YOLO ONNX
    if yolo_onnx_path and os.path.exists(yolo_onnx_path):
        try:
            session = ort.InferenceSession(yolo_onnx_path)
            print(f"‚úÖ YOLO ONNX –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            print(f"   –í—Ö–æ–¥—ã: {[input.name for input in session.get_inputs()]}")
            print(f"   –í—ã—Ö–æ–¥—ã: {[output.name for output in session.get_outputs()]}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO ONNX: {e}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä ONNX
    if classifier_onnx_path and os.path.exists(classifier_onnx_path):
        try:
            session = ort.InferenceSession(classifier_onnx_path)
            print(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä ONNX –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            print(f"   –í—Ö–æ–¥—ã: {[input.name for input in session.get_inputs()]}")
            print(f"   –í—ã—Ö–æ–¥—ã: {[output.name for output in session.get_outputs()]}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ONNX: {e}")

def create_web_pipeline():
    """–°–æ–∑–¥–∞–µ—Ç –≤–µ–±-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π pipeline"""
    print("\nüåê –°–æ–∑–¥–∞–µ–º –≤–µ–±-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π pipeline...")
    
    web_pipeline_code = '''
import onnxruntime as ort
import cv2
import numpy as np
from PIL import Image
import torchvision.transforms as transforms

class WebDamageDetectionPipeline:
    def __init__(self, yolo_onnx_path, classifier_onnx_path):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–±-–ø–∞–π–ø–ª–∞–π–Ω–∞"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ONNX –º–æ–¥–µ–ª–∏
        self.yolo_session = ort.InferenceSession(yolo_onnx_path)
        self.classifier_session = ort.InferenceSession(classifier_onnx_path)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # –ö–ª–∞—Å—Å—ã
        self.yolo_classes = {0: "dirt", 1: "scratch", 2: "dent"}
        self.severity_classes = {
            0: "dirt", 1: "scratch_low", 2: "scratch_med", 3: "scratch_high",
            4: "dent_low", 5: "dent_med", 6: "dent_high"
        }
    
    def detect_damages(self, image_array, confidence_threshold=0.25):
        """–î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é YOLO"""
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è YOLO
        input_image = cv2.resize(image_array, (640, 640))
        input_image = input_image.astype(np.float32) / 255.0
        input_image = np.transpose(input_image, (2, 0, 1))
        input_image = np.expand_dims(input_image, axis=0)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        outputs = self.yolo_session.run(None, {"images": input_image})
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
        # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å NMS –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ confidence
        return outputs
    
    def classify_severity(self, crop_image):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL
        if len(crop_image.shape) == 3:
            crop_pil = Image.fromarray(cv2.cvtColor(crop_image, cv2.COLOR_BGR2RGB))
        else:
            crop_pil = Image.fromarray(crop_image)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        input_tensor = self.transform(crop_pil).unsqueeze(0).numpy()
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        outputs = self.classifier_session.run(None, {"input": input_tensor})
        probabilities = self.softmax(outputs[0])
        
        predicted_class = np.argmax(probabilities)
        confidence = np.max(probabilities)
        
        return predicted_class, confidence
    
    def softmax(self, x):
        """Softmax —Ñ—É–Ω–∫—Ü–∏—è"""
        exp_x = np.exp(x - np.max(x))
        return exp_x / np.sum(exp_x)
    
    def process_image(self, image_array):
        """–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –≠—Ç–∞–ø 1: –î–µ—Ç–µ–∫—Ü–∏—è
        detections = self.detect_damages(image_array)
        
        # –≠—Ç–∞–ø 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        results = []
        for detection in detections:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å
            # crop = extract_crop(image_array, detection['box'])
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
            # severity_class, confidence = self.classify_severity(crop)
            
            # results.append({
            #     'box': detection['box'],
            #     'class': severity_class,
            #     'confidence': confidence
            # })
            pass
        
        return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def create_pipeline():
    return WebDamageDetectionPipeline(
        "onnx_models/yolo_3class.onnx",
        "onnx_models/severity_classifier.onnx"
    )
'''
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–±-–ø–∞–π–ø–ª–∞–π–Ω
    web_pipeline_path = os.path.join(OUTPUT_DIR, "web_pipeline.py")
    with open(web_pipeline_path, 'w', encoding='utf-8') as f:
        f.write(web_pipeline_code)
    
    print(f"‚úÖ –í–µ–±-–ø–∞–π–ø–ª–∞–π–Ω —Å–æ–∑–¥–∞–Ω: {web_pipeline_path}")

def create_requirements():
    """–°–æ–∑–¥–∞–µ—Ç requirements.txt –¥–ª—è –≤–µ–±-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    requirements = '''# –í–µ–±-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
onnxruntime>=1.15.0
opencv-python>=4.6.0
pillow>=9.0.0
numpy>=1.21.0
torchvision>=0.12.0
'''
    
    requirements_path = os.path.join(OUTPUT_DIR, "requirements.txt")
    with open(requirements_path, 'w', encoding='utf-8') as f:
        f.write(requirements)
    
    print(f"‚úÖ Requirements —Å–æ–∑–¥–∞–Ω: {requirements_path}")

def create_readme():
    """–°–æ–∑–¥–∞–µ—Ç README –¥–ª—è –≤–µ–±-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    readme = '''# –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π (ONNX)

## –û–ø–∏—Å–∞–Ω–∏–µ
–î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π:
1. YOLO - –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±–ª–∞—Å—Ç–µ–π –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π (3 –∫–ª–∞—Å—Å–∞)
2. Severity Classifier - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏ (7 –∫–ª–∞—Å—Å–æ–≤)

## –§–∞–π–ª—ã
- `yolo_3class.onnx` - YOLO –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
- `severity_classifier.onnx` - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–µ–ø–µ–Ω–∏ —Ç—è–∂–µ—Å—Ç–∏
- `web_pipeline.py` - –≤–µ–±-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø–∞–π–ø–ª–∞–π–Ω
- `requirements.txt` - –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
pip install -r requirements.txt
```

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
```python
from web_pipeline import create_pipeline
import cv2

# –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
pipeline = create_pipeline()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
image = cv2.imread("test_image.jpg")

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
results = pipeline.process_image(image)
print(results)
```

## –ö–ª–∞—Å—Å—ã
### YOLO (3 –∫–ª–∞—Å—Å–∞):
- dirt - –≥—Ä—è–∑–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏
- scratch - —Ü–∞—Ä–∞–ø–∏–Ω—ã
- dent - –≤–º—è—Ç–∏–Ω—ã

### Severity Classifier (7 –∫–ª–∞—Å—Å–æ–≤):
- dirt - –≥—Ä—è–∑–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏
- scratch_low/med/high - —Å—Ç–µ–ø–µ–Ω—å —Ü–∞—Ä–∞–ø–∏–Ω
- dent_low/med/high - —Å—Ç–µ–ø–µ–Ω—å –≤–º—è—Ç–∏–Ω

## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- YOLO: ~10ms –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- Classifier: ~5ms –Ω–∞ –æ–±–ª–∞—Å—Ç—å
- –û–±—â–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: ~15-20ms –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
'''
    
    readme_path = os.path.join(OUTPUT_DIR, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme)
    
    print(f"‚úÖ README —Å–æ–∑–¥–∞–Ω: {readme_path}")

def main():
    print("üîÑ –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô –í ONNX –î–õ–Ø –í–ï–ë-–†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–Ø")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è ONNX –º–æ–¥–µ–ª–µ–π
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º YOLO –º–æ–¥–µ–ª—å
    yolo_onnx_path = convert_yolo_to_onnx()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    classifier_onnx_path = convert_classifier_to_onnx()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º ONNX –º–æ–¥–µ–ª–∏
    test_onnx_models(yolo_onnx_path, classifier_onnx_path)
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–±-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ñ–∞–π–ª—ã
    create_web_pipeline()
    create_requirements()
    create_readme()
    
    print(f"\n‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ ONNX –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {OUTPUT_DIR}")
    print(f"üåê –í–µ–±-–ø–∞–π–ø–ª–∞–π–Ω –≥–æ—Ç–æ–≤ –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é!")
    
    if yolo_onnx_path and classifier_onnx_path:
        print(f"\nüìã –§–∞–π–ª—ã –¥–ª—è –≤–µ–±-—Å–∞–π—Ç–∞:")
        print(f"  - {yolo_onnx_path}")
        print(f"  - {classifier_onnx_path}")
        print(f"  - {OUTPUT_DIR}/web_pipeline.py")
        print(f"  - {OUTPUT_DIR}/requirements.txt")
        print(f"  - {OUTPUT_DIR}/README.md")

if __name__ == "__main__":
    main()
